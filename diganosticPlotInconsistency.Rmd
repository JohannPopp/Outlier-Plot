---
title: Inconsistencies in the reproduction of figures 5.12 and 5.15 of Hosmer et al.
  2013
author: "Johann Popp"
date: "4 November 2017"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Hosmer et al[^1] have suggested several graphics to identify and investigate extreme and influencing covariate patterns in logistic regression models. These plots where reproduced using the computer software R[^2], taking data from package aplore3[^3] and using package epiR[^4] for the calculation of statistics based on covariate patterns rather then single data rows.  
  

```{r fourPlots, echo=FALSE, message=FALSE}
par(mfrow = c(2,2))

# Load example data
glow <- aplore3::glow500

# Recode RATERISK
glow$raterisk3 <- cut(as.numeric(glow$raterisk), 2)
levels(glow$raterisk3) <- c("less/same", "greater")


# Logistic model from Table 4.16
model <- glm(fracture ~ age + height + priorfrac + momfrac + armassist + raterisk3 + age:priorfrac + momfrac:armassist, data = glow, family = "binomial")

### Convert to covariate patterns
library(epiR)

# aggregate to covariate pattern
cp <- epi.cp(model.frame(model)[-1])
# Number of outcome events per covariate pattern
obs <- as.vector(by(as.numeric(as.factor(model$model[,1]))-1, as.factor(cp$id), sum))
# Estimated outcome probability per covariate pattern
fit <- as.vector(by(model$fitted.values, as.factor(cp$id), min))
# Calculate residuals and influence measures per covariate pattern
res <- epi.cpresids(obs, fit, cp)
# Calculate Change in deviance
deltaDeviance <- res$deviance^2 + ((res$pearson^2*res$leverage)/(1 - res$leverage))
# Put it together in one data.frame
dat <- data.frame(res, deltaDeviance, fit, cp$cov.pattern)


# Plot leverage vs. fit
plot(dat$fit, dat$leverage, xlim = c(0, 0.8), ylim = c(0, 0.08), bty = "n", 
     pch = 16, cex = 0.8, xlab = "Estimated probability", ylab = "Leverage")


# Plot change in Chi-square vs. fit.
plot(dat$fit, dat$deltachi, xlim = c(0, 0.8), ylim = c(0, 18), bty = "n", pch = 16, 
     cex = 0.8, xlab = "Estimated probability", ylab = "Change in Pearson chi-square")


# Plot change in deviance vs. fit.
plot(dat$fit, dat$deltaDeviance, xlim = c(0, 0.8), ylim = c(0, 6), bty = "n", pch = 16,
     cex = 0.8, xlab = "Estimated probability", ylab = "Change in deviance")


# Plot Cook's distance vs. fit
plot(dat$fit, dat$deltabeta, pch = 16, cex = 0.8, xlim = c(0, 0.8), 
     bty = "n", xlab = "Estimated probability", ylab = "Cook's distance")


par(mfrow = c(1,1))

```

   
This works fine for the graphs showings change of Pearson chi-square and change of deviance but the plots of leverage vs. fitted values and Cook's distance vs. fitted values differ substantially from figures 5.12 and 5.15 of the book.  
  
```{r, echo=FALSE}
# Plot leverage vs. fit for covariate patterns against photographed picture
library(png)
img512 <- readPNG("HLS5-12new.png")
plot(1:2, xlim = c(0, 0.8), ylim = c(0, 0.08), bty = "n", xlab = "Estimated probability", ylab = "Leverage", main = "Leverage based on package epiR vs. published figure 5.12")
rasterImage(img512, xleft = -0.03, ybottom = -0.0045, xright = 0.817,ytop = 0.0827)
points(dat$fit, dat$leverage, 
       col = "#FF000090", pch = 1, cex = 1.2, lwd = 1.5)
legend(0, 0.08, pch = c(16, 1), legend = c("Photograph of Fig. 5.12 in\nHosmer et al. 2013", "epiR"), col = c("blue", "red"), cex = 0.8)

# Plot Cook's distance aggregated vs. fit
img515 <- readPNG("HLS5-15new.png")
plot(1:2, pch = 16, cex = 0.8, xlim = c(0, 0.8), ylim = c(0, 0.4),bty = "n", 
     xlab = "Estimated probability", ylab = "Cook's distance", 
     main = "Cook's distance based on package epiR vs. published figure 5.15")
rasterImage(img515, xleft = -0.024, ybottom = -0.022, xright = 0.82, ytop = 0.413)
points(dat$fit, dat$deltabeta, 
       col = "#FF000090", pch = 1, cex = 1.2, lwd = 1.5)
legend(0.3, 0.4, legend = c("Photograph of Fig. 5.15 in\nHosmer et al. 2013", "epiR"),
       pch = c(16, 1), col = c("blue", "red"), cex = 0.8)

```
  
  
With leverages based on non-aggregated n-statistics instead of covariate patterns (m-statistics) the plot can be roughly reproduced, but there are still some points that do not match.

  
```{r, echo=FALSE}
# Plot leverage vs. fit for each case
plot(1:2, xlim = c(0, 0.8), ylim = c(0, 0.08), bty = "n", xlab = "Estimated probability", ylab = "Leverage", main = "Leverage based on non-aggregated data vs. published figure 5.12")
rasterImage(img512, xleft = -0.03, ybottom = -0.0045, xright = 0.817,ytop = 0.0827)
points(fitted.values(model), hatvalues(model), 
       col = "#FF000090", pch = 1, cex = 1.2, lwd = 1.5)
legend(0, 0.08, pch = c(16, 1), col = c("blue", "red"), cex = 0.8,
       legend = c("Photograph of Fig. 5.12 in\nHosmer et al. 2013", "non-aggregated data"))

```
  
  
But this remedy does not work for Cook's distance. The values based on n-statistics are completely different from those printed in the book and those calculated by epiR in magnitude and pattern.

  
```{r, echo=FALSE}
# Plot Cook's distance vs. fit
plot(1:2, pch = 16, cex = 0.8, xlim = c(0, 0.8), ylim = c(0, 0.4),bty = "n", 
     xlab = "Estimated probability", ylab = "Cook's distance", 
     main = "Cook's distance based non-aggrgated vs. published figure 5.15")
rasterImage(img515, xleft = -0.024, ybottom = -0.022, xright = 0.82, ytop = 0.413)
points(fitted.values(model), cooks.distance(model), 
       col = "#FF000090", pch = 1, cex = 1.2, lwd = 1.5)
legend(0.3, 0.4, legend = c("Photograph of Fig. 5.15 in\nHosmer et al. 2013",
                            "Non-aggregated data"),
       pch = c(16, 1), col = c("blue", "red"), cex = 0.8)

```
  
  
I tried out the newer package logisticDx[^5] to calculate the diagnostic statistics. This packackage specializes on diagnostic tests for regression models with binomial response and is explicitely based on the book of Hosmer et al. albeit in its second edition from 2000.
  
  
```{r, echo=FALSE}
# Use leverage based on package logisticDX
library(LogisticDx)
ldx <- dx(model)
plot(1:2, xlim = c(0, 0.8), ylim = c(0, 0.08), bty = "n", xlab = "Estimated probability", ylab = "Leverage", main = "Leverage based on package logisticDX vs. published figure 5.12")
rasterImage(img512, xleft = -0.03, ybottom = -0.0045, xright = 0.817,ytop = 0.0827)
points(ldx$P, ldx$h, 
       col = "#FF000090", pch = 1, cex = 1.2, lwd = 1.5)
legend(0, 0.08, pch = c(16, 1), col = c("blue", "red"), cex = 0.8, 
       legend = c("Photograph of Fig. 5.12 in\nHosmer et al. 2013",
                                           "logisticDX::dx"))

# Compare leverages based on logisticDx with leverages based on original data
plot(1:2, xlim = c(0, 0.8), ylim = c(0, 0.08), bty = "n", xlab = "Estimated probability", ylab = "Leverage", main = "Leverage based on logisticDX::dx vs. original data")
points(fitted.values(model), hatvalues(model), col = "#FF0000", lwd = 1.5, cex = 1.2)
points(ldx$P, ldx$h, col = "#0000FF60", pch = 16)
legend(0, 0.08, pch = c(16, 1), legend = c("logisticDX::dx", "non-aggregated data"), 
       col = c("#0000FF60", "red"), cex = 0.8)

```
  
  
You can see, that the leverages of logisticDX::dx are exactly the same as those calculated from non-aggregated data (n-statistics). We have seen bevore that theese are matching figure 5.12 quite well but not with all the points.
  
When they are calculated with logisticDX::dx, also the values of Cook's distance are fitting well with figure 5.15 despite of some single cases. I guess these are the same as those that do not fit in leverarge.
  
  

```{r, echo=FALSE}
plot(1:2, pch = 16, cex = 0.8, xlim = c(0, 0.8), ylim = c(0, 0.4),bty = "n", 
     xlab = "Estimated probability", ylab = "Cook's distance", 
     main = "Cook's distance based on package logisticDx vs. published figure 5.15")
rasterImage(img515, xleft = -0.024, ybottom = -0.022, xright = 0.82, ytop = 0.413)
points(ldx$P, ldx$dBhat, 
       col = "#FF000090", pch = 1, cex = 1.2, lwd = 1.5)
legend(0.3, 0.4, legend = c("Photograph of Fig. 5.15 in\nHosmer et al. 2013",
                            "logisticDx::dx"),
       pch = c(16, 1), col = c("blue", "red"), cex = 0.8)
```
  
  
Let's see what happens if we multiply the leverage times m, the number of cases in the covariate pattern:

  
```{r, leverage times n, echo=FALSE}
# Leverage of logisticDX:dx times size of covariate pattern
plot(1:2, xlim = c(0, 0.8), ylim = c(0, 0.08), bty = "n", xlab = "Estimated probability", ylab = "Leverage", main = "Leverage based on package logisticDX times m\nvs. published figure 5.12")
rasterImage(img512, xleft = -0.03, ybottom = -0.0045, xright = 0.817,ytop = 0.0827)
points(ldx$P, ldx$h*ldx$n, 
       col = "#FF000090", pch = 1, cex = 1.2, lwd = 1.5)
legend(0, 0.08, pch = c(16, 1), 
       legend = c("Photograph of Fig. 5.12 in\nHosmer et al. 2013", 
                  "logisticDX::dx times m"), col = c("blue", "red"), 
       cex = 0.8)

```
  
  
This fits perfectly. But the Stata manual[^6] gives an other formula:  

The diagonal $h_j = (XVX')_{jj}$ times $M_j  p_j(1 - p_j)$  

where X is the design matrix for the j covariate patterns and V is the covariance matrix, M is the number of cases in covariate pattern j, p is the estimated outcome probability for covariate pattern j.
```{r, Calculate stata formula}
# Leverage following Stata formula

# Extract the design matrix
X <- model.matrix(model)
# Extract data used by the model
datN <- model$model
# aggregate data to covariate patterns
cp <- unique(datN[,-1])
# Extract an indicator of covariate patterns by pasting the values of all the x-values
cp$cpid <- apply(cp, 1, function(x) paste(x, collapse = ""))
# Get the estimated y-probability for each covariate pattern
cp$fit <- model$fitted.values[rownames(cp)]
# Get n-based hat values for each covariate pattern
cp$H <- hatvalues(model)[rownames(cp)]

# create a covariate pattern indicator for the non-aggregated data (Same method as for covairate patterns)
cpid <- apply(datN[,-1], 1, function(x) paste(x, collapse = ""))
# calculate group size for each covariate pattern
m <- tapply(datN[,1], cpid, length)[rank(cp$cpid)]
# (tapply sorts the entries by cpid; [rank(cp$cpid)] sorts back to the original order)

# Aggregate the design matrix to covariate patterns
Xu <- unique(X)
# Extract the variance-covariance matrix of the model
V <- vcov(model)

### This is the formula describet in the Stata reference manual
# Calculate the raw hat values
rawH <- diag(Xu %*% V %*% t(Xu))
# Adjust for covariate pattern
H <- rawH * m * cp$fit * (1-cp$fit)
```

```{r, stata formula plot, echo=FALSE}
plot(1:2, xlim = c(0, 0.8), ylim = c(0, 0.08), bty = "n", xlab = "Estimated probability", ylab = "Leverage", main = "Leverage based on Stata formula vs. published figure 5.12")
rasterImage(img512, xleft = -0.03, ybottom = -0.0045, xright = 0.817,ytop = 0.0827)

points(cp$fit, H, 
       col = "#00906090", pch = 1, cex = 1.7, lwd = 1.5)
points(cp$fit, cp$H*m, 
       col = "#FF000080", pch = 1, cex = 1, lwd = 1.5)

legend(0, 0.08, pch = c(16, 1, 1), legend = c("Photograph of Fig. 5.12 in\nHosmer et al. 2013", "Stata formula", "n-based leverage times m"), col = c("blue", "#00906090", "red"), cex = 0.8)
```
  
You can see that the result is exactly the same the n-based leverages times the group size for each covariate pattern. I would be delighted if somebody who knows more about matrix algebra could proove this instead of only showing it by example as I did.  

  
I also calculated Cook's distance based on these leverages:
  
```{r, Cooks Distance based on leverage times n}
nLev <- ldx$h*ldx$n                   # Leverare times n ("ldx is the dx-obect i have created from the data")
nsPr <- ldx$Pr / sqrt(1 - nLev)       # New standardized Pearson residuals
nCook <-(nsPr^2 * nLev) / (1 - nLev)  # New Cook's distance
```

```{r, plot Cooks Distance based on leverage times n, echo=FALSE}
# logisticDx::dx times n
plot(1:2, pch = 16, cex = 0.8, xlim = c(0, 0.8), ylim = c(0, 0.4),bty = "n", 
     xlab = "Estimated probability", ylab = "Cook's distance", 
     main = "Cook's distance based on package logisticDx with\n leverage times m vs. published figure 5.15")
rasterImage(img515, xleft = -0.024, ybottom = -0.022, xright = 0.82, ytop = 0.413)
points(ldx$P, nCook, 
       col = "#FF000090", pch = 1, cex = 1.2, lwd = 1.5)
legend(0.5, 0.4, 
       legend = c("Photograph of Fig. 5.15 in\nHosmer et al. 2013", 
                  "logisticDx::dx; leverage times n"),
       pch = c(16, 1), col = c("blue", "red"), cex = 0.8)
```
  
  
This looks pretty good as well. 


I decided to recalculate all the statistics my self, based on the formulas given in Hosmer et al 2013.

```{r, Recalculation of diagnostic statistics}
logRegDiagn <- function(model){
  
  ################
  # Basic data extraction and calculation
  
  # Extract non-aggregated data
  datN <- model$model
    # convert to covariate pattern
  cp <- unique(datN[,-1])
  
  # Indicator for covariate patterns
  cpIdN<- apply(datN[,-1], 1, function(x) paste(x, collapse = ""))
  cpIdM <- apply(cp, 1, function(x) paste(x, collapse = ""))
  
  # Size of covariate patterns
  m <- tapply(datN[,1], cpIdN, length)[rank(cpIdM)]
  # Number of cases per covariate pattern
  Y <- tapply(model$y, cpIdN, sum)[rank(cpIdM)]
  # Estimated probability
  Pi <- fitted.values(model)[rownames(cp)]
  
  ####################
  # Basic residuals
  
  # Pearson residual (formula 5.1)
  rPears <- (Y - Pi * m) / sqrt(m * Pi * (1 - Pi))
  
  # Deviance residual (formula 5.3)
  rDev <- ifelse(Y - m * Pi > 0, 1, -1) * 
    (2 * (Y * log(Y / (m * Pi)) + (m - Y) * log((m - Y) / (m * (1 - Pi)))))^(1/2)
  rDev[Y == 0] <- -sqrt(2 * m[Y == 0] * abs(log(1 - Pi[Y == 0])))
  rDev[Y == m] <- sqrt(2 * m[Y == m] * abs(log(Pi[Y == m])))
  
  
  ############
  # Diagnostic statistics to plot
  
  # Leverage
  V <- diag(m * Pi * (1 - Pi))
  X <- unique(model.matrix(model))
  
  H <- V^(1/2) %*% X %*% solve(t(X) %*% V %*% X) %*% t(X) %*% (V^(1/2)) # formula 5.21
  h <- diag(H)

  # Cook's distance (formula 5.24)
  deltaBeta <- rPears^2 * h / (1 - h)^2  
  
  # Change in Pearson chi-square (formula 5.25)
  deltaChi <- rPears^2 / (1 - h)
  
  # Change in deviance (formula 5.26)
  deltaDeviance <- rDev^2 / (1 - h)
  
  
  ################
  # collect output data
  out <- data.frame(m, Y, Pi, rPears, rDev, h, deltaBeta, deltaChi, deltaDeviance, cpIdM, cp)
  rownames(out) <- rownames(cp)
  out
  
}
```


The resulting plots finely fit the figures of the book. I think that the marginal deviations that can be seen are due to my less than perfect scans of the printed graphs.

```{r, echo=FALSE, "plots with recalculated statistics", echo=FALSE}
cp <- logRegDiagn(model)


plot(1:2, xlim = c(0, 0.8), ylim = c(0, 0.08), bty = "n", xlab = "Estimated probability", ylab = "Leverage", main = "Recalculated leverage vs. published figure 5.12")
rasterImage(img512, xleft = -0.03, ybottom = -0.0045, xright = 0.817,ytop = 0.0827)
points(cp$Pi, cp$h, 
       col = "#FF000090", pch = 1, cex = 1.2, lwd = 1.5)
#legend(0, 0.08, pch = c(16, 1), legend = c("Photograph of Fig. 5.12 in\nHosmer et al. 2013", "Recalc. Hosmer formula"), col = c("blue", "red"), cex = 0.8)

plot(1:2, pch = 16, cex = 0.8, xlim = c(0, 0.8), ylim = c(0, 0.4),bty = "n", 
     xlab = "Estimated probability", ylab = "Cook's distance", 
     main = "Re-calculated Cook's distance vs. published figure 5.15")
rasterImage(img515, xleft = -0.024, ybottom = -0.022, xright = 0.82, ytop = 0.413)
points(cp$Pi, cp$deltaBeta, 
       col = "#FF000090", pch = 1, cex = 1.2, lwd = 1.5)
# legend(0.5, 0.4, legend = c("Photograph of Fig. 5.15 in\nHosmer et al. 2013", "Recalculation"),
       # pch = c(16, 1), col = c("blue", "red"))

img513 <- readPNG("HLS5-13new.png")
plot(1:2, xlim = c(0, 0.8), ylim = c(0, 18), bty = "n", xlab = "Estimated probability", ylab = "Change in Pearson chi-square", main = "Change in Pearson chi-square vs. published figure 5.13")
rasterImage(img513, xleft = -0.032, ybottom = -1.1, xright = 0.82, ytop = 16.6)
points(cp$Pi, cp$deltaChi, 
       col = "#FF000090", pch = 1, cex = 1.2, lwd = 1.5)
# legend(0.4, 15, pch = c(16, 1), legend = c("Photograph of Fig. 5.13 in\nHosmer et al. 2013", "Recalculation"), col = c("blue", "red"))


img514 <- readPNG("HLS5-14new.png")
plot(1:2, xlim = c(0, 0.8), ylim = c(0, 6), bty = "n", xlab = "Estimated probability", ylab = "Change in deviance", main = "Change deviance vs. published figure 5.13")
rasterImage(img514, xleft = -0.03, ybottom = -0.38, xright = 0.824, ytop = 6.27)
points(cp$Pi, cp$deltaDeviance,
       col = "#FF000090", pch = 1, cex = 1.2, lwd = 1.5)
# legend(0.3, 6, pch = c(16, 1), legend = c("Photograph of Fig. 5.14 in\nHosmer et al. 2013", "Recalculation"), col = c("blue", "red"))



```

  

  


  


### Summary

There are two R packages epiR and logisticDx that provide functions to calculate diagnostics of outliers and influential covariate patterns for logistic regression models. Non of them exactly reproduces the plots recommended by Hosmer et al. that where produced with Stata. Plots based on epiR differ substatially from the book, those based on logisticDx only marginally. Stata - the program used to produce the plots in the book - uses a different formula but it seems that you can multiply the single case leverages (that are routinely calculated by R) with the group size of the covariate pattern to get the same result. In the end I calculated the statistcs my self in R, using the formulas from the book. The resulting plots fit perfectly with the graphs from the book.



[^2]:  R Core Team (2017). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. URL https://www.R-project.org/.


[^1]: Hosmer, David W., Stanley Lemeshow, und Rodney X. Sturdivant. Applied logistic regression. 3rd Ed. Wiley series in probability and statistics. Hoboken, NJ: Wiley, 2013, p 186 ff.

[^3]:   Luca Braglia (2016). aplore3: Datasets from Hosmer, Lemeshow and Sturdivant, "Applied Logistic Regression" (3rd Ed., 2013). R package version 0.9.   https://CRAN.R-project.org/package=aplore3


[^4]:   Mark Stevenson with contributions from Telmo Nunes, Cord Heuer, Jonathon Marshall, Javier Sanchez, Ron Thornton, Jeno Reiczigel, Jim Robison-Cox, Paola Sebastiani, Peter Solymos, Kazuki Yoshida, Geoff Jones, Sarah Pirikahu, Simon Firestone and Ryan Kyle. (2017). epiR: Tools for the Analysis of Epidemiological Data. R package version 0.9-87. https://CRAN.R-project.org/package=epiR

[^5]:   Chris Dardis (2015). LogisticDx: Diagnostic Tests for Models with a Binomial Response. R package version 0.2. https://CRAN.R-project.org/package=LogisticDx

[^6]: “Logistic Postestimation - Postestimation Tools for Logistic.” In Base Reference Manual, Release 15. College Station, Texas: Stata Press, 2017. https://www.stata.com/bookstore/base-reference-manual/.
